<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Metrics - NLP Fundamentals</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" xintegrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" xintegrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUbGuHTCQ" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" xintegrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .katex-display { display: block; margin: 1em 0; text-align: center; }
        .content-section h1 { margin-bottom: 1.5rem; font-size: 2.25rem; font-weight: 700; color: #6b7280; /* Gray-500 */ }
        .content-section h2 { margin-top: 2rem; margin-bottom: 1rem; font-size: 1.75rem; font-weight: 600; border-bottom: 2px solid #e5e7eb; padding-bottom: 0.5rem; }
        .content-section h3 { margin-top: 1.5rem; margin-bottom: 0.75rem; font-size: 1.35rem; font-weight: 600; }
        .content-section h4 { margin-top: 1.25rem; margin-bottom: 0.5rem; font-size: 1.15rem; font-weight: 600; }
        .content-section p, .content-section ul, .content-section ol { margin-bottom: 1rem; line-height: 1.65; color: #374151; /* Gray-700 */ }
        .content-section ul { list-style-type: disc; margin-left: 1.5rem; }
        .content-section ol { list-style-type: decimal; margin-left: 1.5rem; }
        .content-section code { background-color: #f3f4f6; padding: 0.2em 0.4em; margin: 0; font-size: 85%; border-radius: 3px; color: #4b5563; /* Gray-600 */ }
        .content-section pre { background-color: #f9fafb; /* Gray-50 */ border: 1px solid #e5e7eb; /* Gray-200 */ padding: 1em; border-radius: 0.375rem; /* rounded-md */ overflow-x: auto; margin-bottom: 1rem; }
        .content-section pre code { background-color: transparent; padding: 0; font-size: 90%; }
        .nav-link { padding: 0.5rem 1rem; border-radius: 0.375rem; transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out; }
        .nav-link:hover { background-color: #f3f4f6; /* Gray-100 */ color: #374151; /* Gray-700 */ }
        .nav-link.active { background-color: #6b7280; /* Gray-500 */ color: white; }
        .note { background-color: #eef2ff; /* Indigo-50 */ border-left: 4px solid #6366f1; /* Indigo-500 */ padding: 1rem; margin-top: 1rem; margin-bottom: 1.5rem; border-radius: 0.25rem;}
        .note strong { color: #4f46e5; /* Indigo-600 */ }
        .example-box { background-color: #f9fafb; /* Gray-50 */ border: 1px solid #e5e7eb; /* Gray-200 */ border-left-width: 4px; border-left-color: #9ca3af; /* Gray-400 */ padding: 1rem; margin-top: 1rem; margin-bottom: 1.5rem; border-radius: 0.375rem; }
        .example-box h5 { font-weight: 600; color: #4b5563; /* Gray-600 */ margin-bottom: 0.5rem; }
        .formula-box { background-color: #f3f4f6; padding: 1rem; border-radius: 0.375rem; margin-bottom:1rem; }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <nav class="bg-white shadow-md sticky top-0 z-50">
        <div class="container mx-auto px-6 py-3 flex flex-wrap justify-between items-center">
            <a href="index.html" class="text-xl font-bold text-blue-600">NLP Fundamentals</a>
            <button id="mobile-menu-button" class="md:hidden text-gray-600 hover:text-gray-800 focus:outline-none">
                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path></svg>
            </button>
            <div id="mobile-menu" class="w-full md:w-auto md:flex md:flex-nowrap md:overflow-x-auto space-y-2 md:space-y-0 md:space-x-1 hidden mt-3 md:mt-0">
                <a href="index.html" class="nav-link text-gray-700 block md:inline-block">Home</a>
                <a href="text_processing.html" class="nav-link text-gray-700 block md:inline-block">Text Processing</a>
                <a href="regex.html" class="nav-link text-gray-700 block md:inline-block">Regex</a>
                <a href="language_models.html" class="nav-link text-gray-700 block md:inline-block">Language Models</a>
                <a href="sequence_labelling.html" class="nav-link text-gray-700 block md:inline-block">Sequence Labelling</a>
                <a href="sparse_embeddings.html" class="nav-link text-gray-700 block md:inline-block">Sparse Embeddings</a>
                <a href="word_embeddings.html" class="nav-link text-gray-700 block md:inline-block">Word Embeddings (Neural)</a>
                <a href="recurrent_neural_networks.html" class="nav-link text-gray-700 block md:inline-block">RNNs</a>
                <a href="seq2seq_attention.html" class="nav-link text-gray-700 block md:inline-block">Seq2Seq & Attention</a>
                <a href="transformer_architecture.html" class="nav-link text-gray-700 block md:inline-block">Transformers</a>
                <a href="transformer_models_pretraining.html" class="nav-link text-gray-700 block md:inline-block">Transformer Models</a>
                <a href="finetuning_advanced_llm.html" class="nav-link text-gray-700 block md:inline-block">Fine-tuning LLMs</a>
                <a href="nlp_tasks_applications.html" class="nav-link text-gray-700 block md:inline-block">NLP Tasks</a>
                <a href="evaluation_metrics_nlp.html" class="nav-link text-gray-700 active block md:inline-block">Evaluation Metrics</a>
                <a href="lab_regex.html" class="nav-link text-gray-700 active block md:inline-block">Regex Lab</a>
                <a href="lab_crf.html" class="nav-link text-gray-700 block md:inline-block">CRF Lab</a>
                <a href="lab_bert.html" class="nav-link text-gray-700 block md:inline-block">BERT Lab</a>
                <a href="lab_llama.html" class="nav-link text-gray-700 block md:inline-block">Llama Lab</a>
            </div>
        </div>
    </nav>

    <main class="container mx-auto px-6 py-12 content-section">
        <h1>Part 4: Evaluation Metrics</h1>
        <p>
            Evaluating the performance of NLP models is crucial for understanding their capabilities,
            comparing different approaches, and tracking progress. Different tasks require different
            metrics. This section will focus on common metrics, particularly for text generation.
        </p>

        <section id="rouge">
            <h2>Section 4.1: Metrics for Text Generation</h2>
            <p>Evaluating generated text (e.g., summaries, translations) is challenging because there can be many "correct" outputs. Metrics often compare model-generated text to one or more human-written reference texts.</p>

            <h3>ROUGE (Recall-Oriented Understudy for Gisting Evaluation)</h3>
            <p>
                ROUGE is a set of metrics commonly used for evaluating automatic summarization and machine translation.
                It measures the overlap (n-grams, word sequences, word pairs) between the system-generated summary/translation
                and a set of reference summaries/translations.
            </p>
            <h4>Key Components and Variants:</h4>
            <ul>
                <li>
                    <strong>N-gram Recall (ROUGE-N):</strong> Measures the overlap of n-grams between the system and reference summaries.
                    <div class="formula-box">
                        $\text{ROUGE-N} = \frac{\sum_{S \in \{\text{RefSummaries}\}} \sum_{\text{gram}_n \in S} \text{Count}_{\text{match}}(\text{gram}_n)}{\sum_{S \in \{\text{RefSummaries}\}} \sum_{\text{gram}_n \in S} \text{Count}(\text{gram}_n)}$
                    </div>
                    Where $\text{Count}_{\text{match}}(\text{gram}_n)$ is the maximum number of n-grams co-occurring in a system summary and a set of reference summaries, and $\text{Count}(\text{gram}_n)$ is the number of n-grams in the reference summary.
                    <ul>
                        <li><strong>ROUGE-1:</strong> Overlap of unigrams (individual words). Focuses on content word overlap.</li>
                        <li><strong>ROUGE-2:</strong> Overlap of bigrams. Focuses on short phrase fluency.</li>
                    </ul>
                </li>
                <li>
                    <strong>ROUGE-L (Longest Common Subsequence):</strong> Measures the longest common subsequence (LCS) between the system and reference summaries. An LCS is a sequence of words that appear in the same order in both summaries, but not necessarily contiguously. ROUGE-L takes into account sentence-level structure similarity.
                    The score is computed using F-measure: $F_{lcs} = \frac{(1+\beta^2)R_{lcs}P_{lcs}}{R_{lcs} + \beta^2 P_{lcs}}$, where $R_{lcs}$ is recall and $P_{lcs}$ is precision based on LCS. Often $\beta$ is set to a large value to emphasize recall.
                </li>
                <li>
                    <strong>ROUGE-W (Weighted Longest Common Subsequence):</strong> An extension of ROUGE-L that gives more weight to consecutive matches in the LCS.
                </li>
                <li>
                    <strong>ROUGE-S (Skip-Bigram Co-occurrence Statistics):</strong> Measures the overlap of skip-bigrams, which are pairs of words in their sentence order, allowing for arbitrary gaps.
                </li>
                <li>
                    <strong>ROUGE-SU (Skip-Bigram + Unigram Co-occurrence):</strong> Extends ROUGE-S by also including unigram co-occurrence statistics.
                </li>
            </ul>
            <div class="example-box">
                <h5>Simplified Example: ROUGE-1</h5>
                <p><strong>Reference Summary:</strong> "The cat sat on the mat."</p>
                <p><strong>System Summary 1:</strong> "The cat sat on a mat."</p>
                <p><strong>System Summary 2:</strong> "A dog slept on the rug."</p>
                <p>
                    For ROUGE-1:
                    <ul>
                        <li>Unigrams in Reference: {The, cat, sat, on, the, mat} (Count: 6)</li>
                        <li>Unigrams in System 1: {The, cat, sat, on, a, mat}</li>
                        <li>Matching Unigrams (Ref vs Sys1): {The, cat, sat, on, mat} (Count_match: 5)</li>
                        <li>ROUGE-1 (Sys1) = 5/6 $\approx$ 0.83</li>
                        <br/>
                        <li>Unigrams in System 2: {A, dog, slept, on, the, rug}</li>
                        <li>Matching Unigrams (Ref vs Sys2): {on, the} (Count_match: 2, assuming "the" matches once)</li>
                        <li>ROUGE-1 (Sys2) = 2/6 $\approx$ 0.33</li>
                    </ul>
                    System 1 has a higher ROUGE-1 score, indicating better unigram overlap with the reference.
                </p>
            </div>
            <h4>Interpretation & Considerations:</h4>
            <ul>
                <li>ROUGE scores are typically reported as recall, precision, and F1-score.</li>
                <li>Higher ROUGE scores generally indicate better similarity to reference texts.</li>
                <li>ROUGE is good for measuring content overlap but doesn't directly assess fluency, coherence, or factual correctness.</li>
                <li>The choice of ROUGE variant (N, L, S, SU) depends on what aspect of summary quality is being emphasized. ROUGE-1, ROUGE-2, and ROUGE-L are most commonly reported.</li>
            </ul>
            <div class="note">
                <p><strong>Scalability (ROUGE):</strong> Calculating ROUGE involves comparing n-grams or subsequences. For ROUGE-N, this is relatively efficient. ROUGE-L (LCS) can be computed with dynamic programming, typically $O(m \times n)$ where $m$ and $n$ are lengths of system and reference summaries. For evaluating large outputs or many reference summaries, efficient implementations are important. Standard ROUGE toolkits are available.
                </p>
            </div>
            <p>Other metrics for text generation include BLEU (Bilingual Evaluation Understudy, common in MT), METEOR, CIDEr (for image captioning), and perplexity (for language models). More recently, model-based evaluation (using other pre-trained models to score quality) and human evaluation remain crucial, especially for nuanced aspects of generation quality.</p>
        </section>
        <!--
        <section id="other-metrics">
            <h2>Section 4.2: Metrics for Other NLP Tasks</h2>
            <p>This section would cover metrics for tasks like classification (accuracy, precision, recall, F1), sequence labeling (token accuracy, span-based F1 for NER), etc.</p>
        </section>
        -->

    </main>

    <footer class="bg-gray-800 text-white py-8 mt-12">
        <div class="container mx-auto px-6 text-center">
            <p>&copy; <span id="currentYear"></span> NLP Fundamentals. For educational purposes.</p>
            <p class="text-sm text-gray-400">Content derived from "NLP Exam Preparation" notes.</p>
        </div>
    </footer>

    <script>
        // KaTeX auto-render
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false},
                    {left: "\\[", right: "\\]", display: true}
                ],
                throwOnError : false
            });

            // Set current year in footer
            document.getElementById('currentYear').textContent = new Date().getFullYear();

            // Active Nav Link Highlighting & Mobile Menu Toggle
            const currentLocation = window.location.pathname.split('/').pop() || 'index.html';
            const navLinks = document.querySelectorAll('nav a.nav-link');
            navLinks.forEach(link => {
                if (link.getAttribute('href') === currentLocation) {
                    link.classList.add('active');
                    link.classList.remove('text-gray-700');
                } else {
                    link.classList.remove('active');
                    link.classList.add('text-gray-700');
                }
            });

            const mobileMenuButton = document.getElementById('mobile-menu-button');
            const mobileMenu = document.getElementById('mobile-menu');
            if (mobileMenuButton && mobileMenu) {
                mobileMenuButton.addEventListener('click', function() {
                    mobileMenu.classList.toggle('hidden');
                });
            }
        });
    </script>

</body>
</html>
