<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab: Conditional Random Fields (CRFs) - NLP Fundamentals</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" xintegrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" xintegrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUbGuHTCQ" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" xintegrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .katex-display { display: block; margin: 1em 0; text-align: center; }
        .content-section h1 { margin-bottom: 1.5rem; font-size: 2.25rem; font-weight: 700; color: #e11d48; /* Rose-600 */ }
        .content-section h2 { margin-top: 2rem; margin-bottom: 1rem; font-size: 1.75rem; font-weight: 600; border-bottom: 2px solid #e5e7eb; padding-bottom: 0.5rem; }
        .content-section h3 { margin-top: 1.5rem; margin-bottom: 0.75rem; font-size: 1.35rem; font-weight: 600; }
        .content-section h4 { margin-top: 1.25rem; margin-bottom: 0.5rem; font-size: 1.15rem; font-weight: 600; }
        .content-section p, .content-section ul, .content-section ol { margin-bottom: 1rem; line-height: 1.65; color: #374151; /* Gray-700 */ }
        .content-section ul { list-style-type: disc; margin-left: 1.5rem; }
        .content-section ol { list-style-type: decimal; margin-left: 1.5rem; }
        .content-section code { background-color: #f3f4f6; padding: 0.2em 0.4em; margin: 0; font-size: 85%; border-radius: 3px; color: #4b5563; /* Gray-600 */ }
        .content-section pre { background-color: #f9fafb; /* Gray-50 */ border: 1px solid #e5e7eb; /* Gray-200 */ padding: 1em; border-radius: 0.375rem; /* rounded-md */ overflow-x: auto; margin-bottom: 1rem; }
        .content-section pre code { background-color: transparent; padding: 0; font-size: 90%; color: #1f2937; }
        .content-section table { width: 100%; margin-bottom: 1rem; border-collapse: collapse; box-shadow: 0 1px 3px 0 rgba(0,0,0,.1), 0 1px 2px 0 rgba(0,0,0,.06); border-radius: 0.5rem; overflow: hidden;}
        .content-section th, .content-section td { border: 1px solid #e5e7eb; padding: 0.75rem 1rem; text-align: left; font-size: 0.875rem; }
        .content-section th { background-color: #f9fafb; /* Gray-50 */ font-weight: 600; color: #1f2937; /* Gray-800 */ }
        .content-section tr:nth-child(even) { background-color: #f9fafb; }
        .nav-link { padding: 0.5rem 1rem; border-radius: 0.375rem; transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out; }
        .nav-link:hover { background-color: #ffe4e6; /* Rose-100 */ color: #be123c; /* Rose-700 */ }
        .nav-link.active { background-color: #e11d48; /* Rose-600 */ color: white; }
        .note { background-color: #eef2ff; /* Indigo-50 */ border-left: 4px solid #6366f1; /* Indigo-500 */ padding: 1rem; margin-top: 1rem; margin-bottom: 1.5rem; border-radius: 0.25rem;}
        .note strong { color: #4f46e5; /* Indigo-600 */ }
        .example-box { background-color: #fff1f2; /* Rose-50 */ border: 1px solid #fecdd3; /* Rose-200 */ border-left-width: 4px; border-left-color: #fda4af; /* Rose-300 */ padding: 1rem; margin-top: 1rem; margin-bottom: 1.5rem; border-radius: 0.375rem; }
        .example-box h5 { font-weight: 600; color: #be123c; /* Rose-700 */ margin-bottom: 0.5rem; }
        .formula-box { background-color: #f3f4f6; padding: 1rem; border-radius: 0.375rem; margin-bottom:1rem; text-align:center; }
        .code-description { background-color: #f8f8f8; border: 1px solid #eee; padding: 1em; margin-bottom: 1em; border-radius: 5px; }
        .code-description h5 { font-weight: bold; margin-bottom: 0.5em; color: #555; }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <nav class="bg-white shadow-md sticky top-0 z-50">
        <div class="container mx-auto px-6 py-3 flex flex-wrap justify-between items-center">
            <a href="index.html" class="text-xl font-bold text-blue-600">NLP Fundamentals</a>
            <button id="mobile-menu-button" class="md:hidden text-gray-600 hover:text-gray-800 focus:outline-none">
                <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path></svg>
            </button>
            <div id="mobile-menu" class="w-full md:w-auto md:flex md:flex-nowrap md:overflow-x-auto space-y-2 md:space-y-0 md:space-x-1 hidden mt-3 md:mt-0">
                <a href="index.html" class="nav-link text-gray-700 block md:inline-block">Home</a>
                <a href="text_processing.html" class="nav-link text-gray-700 block md:inline-block">Text Processing</a>
                <a href="regex.html" class="nav-link text-gray-700 block md:inline-block">Regex</a>
                <a href="language_models.html" class="nav-link text-gray-700 block md:inline-block">Language Models</a>
                <a href="sequence_labelling.html" class="nav-link text-gray-700 block md:inline-block">Sequence Labelling</a>
                <a href="sparse_embeddings.html" class="nav-link text-gray-700 block md:inline-block">Sparse Embeddings</a>
                <a href="basic_text_processing_foundations.html" class="nav-link text-gray-700 block md:inline-block">Basic Text Processing</a>
                <a href="word_embeddings.html" class="nav-link text-gray-700 block md:inline-block">Word Embeddings (Neural)</a>
                <a href="recurrent_neural_networks.html" class="nav-link text-gray-700 block md:inline-block">RNNs</a>
                <a href="seq2seq_attention.html" class="nav-link text-gray-700 block md:inline-block">Seq2Seq & Attention</a>
                <a href="transformer_architecture.html" class="nav-link text-gray-700 block md:inline-block">Transformers</a>
                <a href="transformer_models_pretraining.html" class="nav-link text-gray-700 block md:inline-block">Transformer Models</a>
                <a href="finetuning_advanced_llm.html" class="nav-link text-gray-700 block md:inline-block">Fine-tuning LLMs</a>
                <a href="nlp_tasks_applications.html" class="nav-link text-gray-700 block md:inline-block">NLP Tasks</a>
                <a href="evaluation_metrics_nlp.html" class="nav-link text-gray-700 block md:inline-block">Evaluation Metrics</a>
                <a href="lab_regex.html" class="nav-link text-gray-700 block md:inline-block">Regex Lab</a>
                <a href="lab_crf.html" class="nav-link text-gray-700 active block md:inline-block">CRF Lab</a>
                <a href="lab_bert.html" class="nav-link text-gray-700 block md:inline-block">BERT Lab</a>
                <a href="lab_llama.html" class="nav-link text-gray-700 block md:inline-block">Llama Lab</a>
            </div>
        </div>
    </nav>

    <main class="container mx-auto px-6 py-12 content-section">
        <h1>Lab 2: Conditional Random Fields (CRFs) for Sequence Labeling</h1>
        <p>
            Conditional Random Fields (CRFs) are a class of statistical modeling methods often applied
            to structured prediction tasks, most notably sequence labeling in NLP. They offer a
            probabilistic framework for segmenting and labeling sequential data.
        </p>

        <section id="lab-crf-experiments">
            <h2>2.1. Analysis of CRF Lab Experiments</h2>
            <p>
                The lab experiments explore NER using CRFs, focusing on the impact of different feature engineering strategies and CRF training model configurations. The dataset consists of 12751 training sentences and 76 test sentences, with a maximum of 20 training iterations for most tasks. The <code>exec_task(...)</code> function orchestrates each experiment.
            </p>

            <h4>Core Lab Components:</h4>
            <div class="code-description">
                <h5><code>create_dataset(max_files=None)</code>:</h5>
                <p>Loads parsed OntoNotes data, splits into 90% train / 10% test. Processes sentences into <code>(token, POS_tag, NER_IOB_tag)</code> tuples. Filters sentences with 'XX' or 'VERB' POS tags (potential parsing issues/dataset characteristics).</p>
            </div>
            <div class="code-description">
                <h5>Feature Extraction Functions (<code>word2features</code>):</h5>
                <p>Convert words into feature dictionaries for the CRF.</p>
                <ul>
                    <li><strong><code>task1_word2features(sent, i)</code>:</strong> Basic features: current word/POS, previous/next word (lowercase)/POS, BOS/EOS flags.</li>
                    <li><strong><code>task2_word2features(sent, i)</code>:</strong> Enhanced features: includes all from task1, plus for current, previous, and next words: word shape (lower, isupper, istitle, isdigit), word suffix (last 3 chars), and POS tag prefix (first 2 chars).</li>
                </ul>
            </div>
             <div class="code-description">
                <h5>Sentence Conversion Utilities:</h5>
                <ul>
                    <li><code>sent2features(sent, word2features_func)</code>: Applies chosen <code>word2features</code> to each word.</li>
                    <li><code>sent2labels(sent)</code>: Extracts IOB labels.</li>
                    <li><code>sent2tokens(sent)</code>: Extracts tokens.</li>
                </ul>
            </div>
            <div class="code-description">
                <h5>CRF Model Training Functions (all use <code>lbfgs</code> algorithm):</h5>
                <ul>
                    <li><strong><code>task1_train_crf_model(X_train, Y_train, max_iter, labels)</code>:</strong> <code>c1=0.1</code> (L1 penalty), <code>c2=0.1</code> (L2 penalty), <code>max_iterations=max_iter</code>, <code>all_possible_transitions=False</code> (only observed transitions).</li>
                    <li><strong><code>task3_train_crf_model(...)</code>:</strong> Same as task1 but <code>c1=200</code> (stronger L1 regularization for sparsity).</li>
                    <li><strong><code>task4_train_crf_model(...)</code>:</strong> Same as task1 but <code>all_possible_transitions=True</code> (learns weights for unobserved transitions).</li>
                    <li><strong><code>task5_train_crf_model(...)</code>:</strong> Uses <code>RandomizedSearchCV</code> for <code>c1</code>, <code>c2</code>. Optimizes for weighted flat F1, 3-fold CV, 50 candidates. Base CRF uses <code>all_possible_transitions=True</code>.</li>
                </ul>
            </div>


            <h3 id="lab-crf-task1" class="mt-6">Task 1: Baseline Features, Basic Training</h3>
            <p><strong>Feature Function:</strong> <code>task1_word2features</code> (basic word/POS context, BOS/EOS).</p>
            <p><strong>Training Function:</strong> <code>task1_train_crf_model</code> (<code>c1=0.1, c2=0.1, all_possible_transitions=False</code>).</p>
            <p><strong>Example Training Feature (from logs):</strong> <code>{'word': 'have', 'postag': 'VBP', '-1:word.lower()': 'people', '-1:postag': 'NNS', '+1:word.lower()': 'long', '+1:postag': 'RB'}</code>.</p>
            <p><strong>Performance Highlights (F1 from logs):</strong> B-GPE (0.69), I-GPE (0.00), B-PERSON (0.51), I-PERSON (0.68), B-ORG (0.40), I-ORG (0.53). Overall Micro F1: 0.54.</p>
            <p><strong>Top Observation Features (Examples from logs):</strong></p>
            <ul>
                <li>For $y=\text{'B-DATE'}$, <code>word:today</code> (+2.506), <code>postag:NN</code> (+1.519).</li>
                <li>For $y=\text{'B-GPE'}$, <code>word:US</code> (+2.947), <code>postag:NNP</code> (+2.155).</li>
                <li>For $y=\text{'B-PERSON'}$, <code>postag:NNP</code> (+3.344), <code>-1:word.lower():president</code> (+1.955).</li>
                <li>For $y=\text{'O'}$, <code>EOS</code> (+6.676), <code>BOS</code> (+3.138), <code>postag:NNP</code> (-4.241, strong negative).</li>
            </ul>
            <p><strong>Label Transition Weights (Examples from logs):</strong> Strong positive for B-DATE $\rightarrow$ I-DATE (+6.261), O $\rightarrow$ O (+5.649). O $\rightarrow$ B-PERSON (+3.415) is a likely start.</p>
            <p><strong>Interpretation:</strong> Moderate baseline performance. Relies heavily on direct lexical cues (specific words like "US", "today") and POS tags (NNP for entities). The model struggles with continuation tags like I-GPE (F1=0.00) and many other less frequent entity types, indicating the feature set is too simple for nuanced distinctions or these entities are rare. The negative weight for NNP being 'O' is logical. High B-GPE recall (0.83) vs. precision (0.59) suggests it identifies many geographical entities but also over-generates them.</p>

            <h3 id="lab-crf-task2" class="mt-6">Task 2: Enhanced Features, Basic Training</h3>
            <p><strong>Feature Function:</strong> <code>task2_word2features</code> (adds word shape, suffix, POS prefix for current/prev/next words).</p>
            <p><strong>Training Function:</strong> <code>task1_train_crf_model</code> (same as Task 1).</p>
            <p><strong>Example Training Feature (from logs):</strong> <code>{'word': 'have', 'postag': 'VBP', 'word.lower()': 'have', 'word.isupper()': False, ..., 'word.suffix': 'ave', 'postag[:2]': 'VB', ...}</code>.</p>
            <p><strong>Performance Highlights (F1 from logs):</strong> B-GPE (0.69), I-GPE (0.00), B-PERSON (0.69, up), I-PERSON (0.81, up), B-ORG (0.46, up), I-ORG (0.64, up). Overall Micro F1: 0.66 (up from 0.54).</p>
            <p><strong>Top Observation Features (Examples from logs):</strong> Features like <code>word.suffix:day</code> (+2.210 for B-DATE), <code>word.lower():us</code> (+1.688 for B-GPE), and <code>word.istitle()</code> (+1.201 for B-PERSON) now appear with high weights.</p>
            <p><strong>Interpretation:</strong> The richer orthographic and morphological features significantly boost NER performance, especially for PERSON and ORG entities. Features like <code>word.istitle()</code> are strong indicators for proper nouns. This task clearly shows the impact of feature engineering: better features lead to better model performance with the same training algorithm.</p>

            <h3 id="lab-crf-task3" class="mt-6">Task 3: Enhanced Features, Strong L1 Regularization</h3>
            <p><strong>Feature Function:</strong> <code>task2_word2features</code> (same rich features as Task 2).</p>
            <p><strong>Training Function:</strong> <code>task3_train_crf_model</code> (key difference: <code>c1=200</code> for strong L1 penalty).</p>
            <p><strong>Performance Highlights (F1 from logs):</strong> Dramatic decline. B-GPE (0.43), B-PERSON (0.12). Overall Micro F1: 0.18.</p>
            <p><strong>Feature/Transition Weights (from logs):</strong> Magnitudes considerably smaller than Task 2.</p>
            <p><strong>Interpretation:</strong> The strong L1 regularization (<code>c1=200</code>) likely zeroed out too many feature weights, leading to an overly sparse and underfit model. Despite having rich features, the model couldn't learn effectively. This highlights that aggressive regularization can be detrimental if not tuned properly.</p>

            <h3 id="lab-crf-task4" class="mt-6">Task 4: Enhanced Features, All Possible Transitions</h3>
            <p><strong>Feature Function:</strong> <code>task2_word2features</code> (rich features).</p>
            <p><strong>Training Function:</strong> <code>task4_train_crf_model</code> (key difference: <code>all_possible_transitions=True</code>; <code>c1, c2</code> back to <code>0.1</code>).</p>
            <p><strong>Performance Highlights (F1 from logs):</strong> Mixed. Overall Micro F1 (0.59) lower than Task 2. B-GPE (0.69), B-PERSON (0.59, worse than T2), I-PERSON (0.82, slightly better than T2), B-ORG (0.08, much worse).</p>
            <p><strong>Interpretation:</strong> Allowing all possible transitions means the model considers transitions not seen in training. While this could theoretically help generalize, in this case, it seems to have degraded performance for some entity types (especially B-ORG), perhaps by introducing noise or diluting learned patterns from observed transitions. The improvement in I-PERSON might suggest it helped with some specific continuation patterns not well-covered otherwise.</p>

            <h3 id="lab-crf-task5" class="mt-6">Task 5: Enhanced Features, Hyperparameter Optimization</h3>
            <p><strong>Feature Function:</strong> <code>task2_word2features</code> (rich features).</p>
            <p><strong>Training Function:</strong> <code>task5_train_crf_model</code> (<code>RandomizedSearchCV</code> for <code>c1, c2</code>; base CRF uses <code>all_possible_transitions=True</code>).</p>
            <p><strong>Best Hyperparameters Found (from logs):</strong> c1 = 0.154, c2 = 0.025.</p>
            <p><strong>Best Micro F1 during search (from logs):</strong> 0.4907.</p>
            <p><strong>Performance (final model with best params, from logs):</strong> B-GPE F1 (0.61), B-PERSON (0.36). Overall Micro F1: 0.40.</p>
            <p><strong>Interpretation:</strong> Hyperparameter optimization did not yield improvements and resulted in performance worse than Task 2 and Task 1. The best score found during the search (0.49) was already low. This suggests issues like: the underlying trainer in <code>task5_train_crf_model</code> might be less effective, the search space/iterations insufficient, or overfitting to CV splits. The <code>UndefinedMetricWarning</code> messages during HPO also indicate problems. This task underscores that HPO is not a magic bullet and depends heavily on the base model, search strategy, and data.</p>

            <h4 class="mt-8">Comparative Performance Summary & Discussion</h4>
            <div class="overflow-x-auto">
                <table>
                    <thead>
                        <tr>
                            <th>Task</th><th>Feature Set</th><th>Training Key Params</th><th>Micro F1</th><th>B-GPE F1</th><th>B-PERSON F1</th><th>I-PERSON F1</th><th>B-ORG F1</th><th>Comment</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>Task 1</td><td>Basic</td><td><code>c1=0.1, c2=0.1, APT=F</code></td><td>0.54</td><td>0.69</td><td>0.51</td><td>0.68</td><td>0.40</td><td>Baseline performance.</td></tr>
                        <tr><td>Task 2</td><td>Enhanced</td><td><code>c1=0.1, c2=0.1, APT=F</code></td><td>0.66</td><td>0.69</td><td>0.69</td><td>0.81</td><td>0.46</td><td><strong>Best overall.</strong> Richer features significantly helped.</td></tr>
                        <tr><td>Task 3</td><td>Enhanced</td><td><code>c1=200, APT=F</code></td><td>0.18</td><td>0.43</td><td>0.12</td><td>0.16</td><td>0.00</td><td>Strong L1 penalty likely caused underfitting.</td></tr>
                        <tr><td>Task 4</td><td>Enhanced</td><td><code>c1=0.1, c2=0.1, APT=T</code></td><td>0.59</td><td>0.69</td><td>0.59</td><td>0.82</td><td>0.08</td><td><code>all_possible_transitions=True</code> had mixed results, hurt B-ORG.</td></tr>
                        <tr><td>Task 5</td><td>Enhanced</td><td>HPO (<code>APT=T</code> base)</td><td>0.40</td><td>0.61</td><td>0.36</td><td>0.11</td><td>0.41</td><td>HPO failed to find better parameters, performed poorly.</td></tr>
                    </tbody>
                </table>
                <p class="text-xs mt-1">APT = all_possible_transitions</p>
            </div>
            <p><strong>Discussion on Performance Differences:</strong></p>
            <ul>
                <li><strong>Feature Engineering is Key (Task 1 vs. Task 2):</strong> The most significant jump in performance came from enhancing the feature set in Task 2. Adding orthographic features (case, digit checks) and morphological features (suffixes, POS prefixes) provided the CRF with more discriminative information, leading to better identification of entities, especially PERSON and ORG. This is a classic lesson in traditional ML: feature quality heavily influences model performance.</li>
                <li><strong>Regularization Impact (Task 2 vs. Task 3):</strong> Task 3 demonstrates that overly strong L1 regularization (<code>c1=200</code>) can be detrimental. While L1 promotes sparsity (useful for high-dimensional feature spaces), too much can eliminate useful features, leading to underfitting and poor generalization, as seen by the drastic drop in F1 scores.</li>
                <li><strong>Transition Handling (Task 2 vs. Task 4):</strong> Setting <code>all_possible_transitions=True</code> in Task 4, which allows the model to learn weights for transitions not explicitly seen in training data, did not universally improve performance over Task 2 (where it was <code>False</code>). While it slightly helped I-PERSON, it severely hurt B-ORG. This suggests that for this dataset and feature set, allowing unseen transitions might have introduced noise or less reliable patterns for some entity types, or that the default transition probabilities learned from observed data in Task 2 were more robust.</li>
                <li><strong>Hyperparameter Optimization Challenges (Task 5):</strong> Task 5's HPO attempt yielded the worst results among tasks using enhanced features. This highlights that HPO is sensitive to the search space, number of iterations, cross-validation strategy, and the stability of the underlying training function. The poor result suggests that the HPO process might have converged to a suboptimal local minimum or that the base model configuration within the HPO (<code>task5_train_crf_model</code> with <code>all_possible_transitions=True</code>) was itself not as strong as the simpler <code>task1_train_crf_model</code> used in Task 2. The <code>UndefinedMetricWarning</code>s during HPO further point to potential instability with many hyperparameter combinations.</li>
            </ul>
            <p>In summary, for this CRF lab on NER, a rich feature set combined with moderate default regularization (as in Task 2) provided the best results. Aggressive regularization or changes to transition handling without careful tuning did not prove beneficial, and the HPO attempt was unsuccessful, possibly due to the search setup or inherent limitations of the training function used in that specific task.</p>
        </section>

        <section id="lab-crf-variations">
            <h2>2.2. CRF Variations</h2>
            <ul>
                <li><strong>Higher-Order CRFs:</strong> Extend dependencies beyond adjacent labels (e.g., $y_t$ depends on $y_{t-1}, y_{t-2}$). Captures more complex patterns but increases computational complexity.</li>
                <li><strong>BiLSTM-CRF:</strong> Popular hybrid. BiLSTM learns rich contextualized features, fed to a CRF layer that models label dependencies and predicts optimal label sequence. BiLSTM excels at automatic feature extraction; CRF layer enforces sequence constraints.</li>
                <li><strong>Dynamic CRFs (DCRFs) & Latent-Dynamic CRFs (LDCRFs):</strong> Advanced extensions incorporating latent variables or modeling more complex graphical structures. LDCRFs assume hidden state variables associated with labels. Training can be challenging.</li>
            </ul>
        </section>

        <section id="lab-crf-uses-limitations">
            <h2>2.3. Uses and Limitations of CRFs in NLP</h2>
            <h4>Uses (Recap):</h4>
            <p>NER, POS Tagging, Shallow Parsing, Bioinformatics, Text Segmentation, Information Extraction.</p>
            <h4>Limitations:</h4>
            <ul>
                <li><strong>Training Time:</strong> Can be computationally intensive and slow, especially with large datasets/features. Complexity can be quadratic in label set size and nearly quadratic in training sample size for linear chains.</li>
                <li><strong>Feature Engineering:</strong> Performance heavily depends on manually designed features (time-consuming, requires domain expertise). Key motivation for shift to deep learning.</li>
                <li><strong>Overfitting:</strong> Prone with many features if regularization is inadequate or features are noisy.</li>
                <li><strong>Complexity with Large Label/Feature Sets:</strong> Cost scales, potentially impractical without approximations.</li>
                <li><strong>Difficulty with Very Long-Range Dependencies:</strong> Standard linear-chain CRFs might struggle, as primary dependencies are local.</li>
            </ul>
            <p>Computational demands and feature engineering burden drove exploration of deep learning models (LSTMs, Transformers) which offer automatic feature learning.</p>
            <div class="note">
                <p><strong>Scalability (CRF Lab Insights):</strong> The lab experiments highlight that feature engineering is critical. While CRFs can handle many features, training time can be a bottleneck (max_iter=20 in labs). The choice of training algorithm and hyperparameters (Task 3 vs. Task 2, Task 5 results) significantly impacts performance and convergence, affecting practical scalability. For larger datasets than used in the lab, the computational cost of training a CRF with a rich feature set would be a major consideration.</p>
            </div>
        </section>

    </main>

    <footer class="bg-gray-800 text-white py-8 mt-12">
        <div class="container mx-auto px-6 text-center">
            <p>&copy; <span id="currentYear"></span> NLP Fundamentals & Labs. For educational purposes.</p>
            <p class="text-sm text-gray-400">Content derived from "NLP Exam Preparation" notes and "NLP Labs Detailed Notes".</p>
        </div>
    </footer>

    <script>
        // KaTeX auto-render
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false},
                    {left: "\\[", right: "\\]", display: true}
                ],
                throwOnError : false
            });

            // Set current year in footer
            document.getElementById('currentYear').textContent = new Date().getFullYear();

            // Active Nav Link Highlighting & Mobile Menu Toggle
            const currentLocation = window.location.pathname.split('/').pop() || 'index.html';
            const navLinks = document.querySelectorAll('nav a.nav-link');
            navLinks.forEach(link => {
                if (link.getAttribute('href') === currentLocation) {
                    link.classList.add('active');
                    link.classList.remove('text-gray-700');
                } else {
                    link.classList.remove('active');
                    link.classList.add('text-gray-700');
                }
            });

            const mobileMenuButton = document.getElementById('mobile-menu-button');
            const mobileMenu = document.getElementById('mobile-menu');
            if (mobileMenuButton && mobileMenu) {
                mobileMenuButton.addEventListener('click', function() {
                    mobileMenu.classList.toggle('hidden');
                });
            }
        });
    </script>

</body>
</html>
